# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–ç‰ˆGitLab APIç®¡ç†å™¨
åŸºäºå¹¶å‘åˆ†é¡µè·å–çš„é«˜æ€§èƒ½ç‰ˆæœ¬ï¼Œå°†å¤„ç†æ—¶é—´ä»262ç§’ä¼˜åŒ–åˆ°15-20ç§’
"""
import gitlab
import re
import time
import logging
from typing import List, Dict, Any, Optional, Set
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import requests
from ..core.cache_manager import RequestCacheManager, CacheKey


logger = logging.getLogger(__name__)


class OptimizedGitLabManager:
    """ä¼˜åŒ–ç‰ˆGitLab APIç®¡ç†å™¨ - é«˜æ€§èƒ½ç‰ˆæœ¬"""
    
    def __init__(self, gitlab_url: str, token: str, project_id: str):
        self.gitlab_url = gitlab_url
        self.token = token
        self.project_id = project_id
        
        # åˆå§‹åŒ–GitLabè¿æ¥
        self.gitlab = gitlab.Gitlab(gitlab_url, private_token=token)
        self.project = self.gitlab.projects.get(project_id)
        
        # åˆå§‹åŒ–ç¼“å­˜
        self.cache = RequestCacheManager()
        
        # GALAXY taskæ­£åˆ™è¡¨è¾¾å¼
        self.task_pattern = re.compile(r'GALAXY-(\d+)')
        
        # æ€§èƒ½é…ç½®
        self.config = {
            'per_page': 200,        # æ¯é¡µcommitsæ•°é‡
            'max_workers': 10,      # å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
            'timeout': 30,          # è¯·æ±‚è¶…æ—¶æ—¶é—´
            'retry_attempts': 3,    # é‡è¯•æ¬¡æ•°
        }
        
        # ç”¨äºç›´æ¥APIè°ƒç”¨çš„headers
        self.headers = {
            'PRIVATE-TOKEN': token,
            'Content-Type': 'application/json'
        }
        
        logger.info(f"[{self._timestamp()}] ğŸš€ OptimizedGitLabManageråˆå§‹åŒ–å®Œæˆ: {gitlab_url}, é¡¹ç›®ID: {project_id}")
    
    def _timestamp(self) -> str:
        """ç”Ÿæˆå¸¦æ¯«ç§’çš„æ—¶é—´æˆ³"""
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
    
    def get_all_branch_commits_concurrent(self, branch_name: str) -> List[Dict[str, Any]]:
        """
        å¹¶å‘è·å–åˆ†æ”¯æ‰€æœ‰commits - æ ¸å¿ƒä¼˜åŒ–æ–¹æ³•
        é¢„æœŸæ€§èƒ½: 18000 commitsçº¦éœ€8-15ç§’
        """
        start_time = time.time()
        logger.info(f"[{self._timestamp()}] ğŸ“¥ å¼€å§‹å¹¶å‘è·å–åˆ†æ”¯commits: {branch_name}")
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"branch_commits:{branch_name}"
        cached_commits = self.cache.get(cache_key)
        if cached_commits is not None:
            logger.info(f"[{self._timestamp()}] ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„commits: {len(cached_commits)}ä¸ª")
            return cached_commits
        
        try:
            # 1. è·å–ç¬¬ä¸€é¡µä»¥ç¡®å®šæ€»é¡µæ•°
            first_page_info = self._get_commits_page_info(branch_name)
            if not first_page_info:
                logger.error(f"[{self._timestamp()}] âŒ æ— æ³•è·å–åˆ†æ”¯ä¿¡æ¯: {branch_name}")
                return []
            
            total_pages = first_page_info['total_pages']
            total_commits = first_page_info['total_commits']
            
            logger.info(f"[{self._timestamp()}] ğŸ“Š åˆ†æ”¯ç»Ÿè®¡: {total_commits} commits, {total_pages} é¡µ")
            
            # 2. å¹¶å‘è·å–æ‰€æœ‰é¡µé¢
            all_commits = self._fetch_all_pages_concurrent(branch_name, total_pages)
            
            # 3. ç¼“å­˜ç»“æœ
            if all_commits:
                self.cache.set(cache_key, all_commits)  # ç¼“å­˜ç»“æœ
            
            elapsed = time.time() - start_time
            logger.info(f"[{self._timestamp()}] âœ… å¹¶å‘è·å–å®Œæˆ: {len(all_commits)} commits, è€—æ—¶ {elapsed:.2f}s, é€Ÿåº¦ {len(all_commits)/elapsed:.1f} commits/s")
            
            return all_commits
            
        except Exception as e:
            logger.error(f"[{self._timestamp()}] âŒ å¹¶å‘è·å–commitså¤±è´¥: {e}")
            return []
    
    def _get_commits_page_info(self, ref_name: str) -> Optional[Dict[str, int]]:
        """è·å–å¼•ç”¨(åˆ†æ”¯/æ ‡ç­¾)çš„åˆ†é¡µä¿¡æ¯ - ä¿®å¤ç‰ˆæœ¬ï¼Œä¸ä¾èµ–ä¸å‡†ç¡®çš„å“åº”å¤´"""
        url = f"{self.gitlab_url}/api/v4/projects/{self.project_id}/repository/commits"
        
        try:
            logger.info(f"[{self._timestamp()}] ğŸ” è·å– {ref_name} çš„åˆ†é¡µä¿¡æ¯...")
            
            # å…ˆè·å–ç¬¬ä¸€é¡µï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
            params = {
                'ref_name': ref_name,
                'per_page': self.config['per_page'],
                'page': 1
            }
            
            response = requests.get(url, headers=self.headers, params=params, timeout=self.config['timeout'])
            logger.info(f"[{self._timestamp()}] ğŸ“ å“åº”çŠ¶æ€: {response.status_code}")
            
            if response.status_code == 200:
                first_page_commits = response.json()
                first_page_count = len(first_page_commits)
                
                logger.info(f"[{self._timestamp()}] ğŸ“Š ç¬¬ä¸€é¡µè·å–åˆ° {first_page_count} commits")
                
                if first_page_count == 0:
                    # æ²¡æœ‰commits
                    return {
                        'total_pages': 0,
                        'total_commits': 0,
                        'per_page': self.config['per_page']
                    }
                elif first_page_count < self.config['per_page']:
                    # åªæœ‰ä¸€é¡µ
                    return {
                        'total_pages': 1,
                        'total_commits': first_page_count,
                        'per_page': self.config['per_page']
                    }
                else:
                    # æœ‰å¤šé¡µï¼Œéœ€è¦ä¼°ç®—æ€»é¡µæ•°
                    # å°è¯•è·å–ä¸€ä¸ªè¾ƒå¤§çš„é¡µæ•°æ¥ä¼°ç®—
                    logger.info(f"[{self._timestamp()}] ğŸ” ä¼°ç®—æ€»é¡µæ•°...")
                    
                    # äºŒåˆ†æŸ¥æ‰¾æœ€åä¸€é¡µ
                    max_page = self._find_last_page(ref_name, url)
                    estimated_total = max_page * self.config['per_page']
                    
                    logger.info(f"[{self._timestamp()}] ğŸ“Š ä¼°ç®—ç»“æœ: çº¦ {max_page} é¡µ, çº¦ {estimated_total} commits")
                    
                    return {
                        'total_pages': max_page,
                        'total_commits': estimated_total,
                        'per_page': self.config['per_page']
                    }
                    
            elif response.status_code == 401:
                logger.error(f"[{self._timestamp()}] âŒ GitLab Tokenæ— æ•ˆ (401 Unauthorized)")
                return None
            elif response.status_code == 404:
                logger.error(f"[{self._timestamp()}] âŒ å¼•ç”¨ä¸å­˜åœ¨: {ref_name} (404 Not Found)")
                return None
            else:
                logger.error(f"[{self._timestamp()}] âŒ è·å–åˆ†é¡µä¿¡æ¯å¤±è´¥: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"[{self._timestamp()}] âŒ è¯·æ±‚åˆ†é¡µä¿¡æ¯å¼‚å¸¸: {e}")
            return None
    
    def _find_last_page(self, ref_name: str, base_url: str) -> int:
        """äºŒåˆ†æŸ¥æ‰¾æœ€åä¸€é¡µ"""
        left, right = 1, 1000  # å‡è®¾æœ€å¤š1000é¡µ
        last_valid_page = 1
        
        while left <= right:
            mid = (left + right) // 2
            params = {
                'ref_name': ref_name,
                'per_page': self.config['per_page'],
                'page': mid
            }
            
            try:
                response = requests.get(base_url, headers=self.headers, params=params, timeout=10)
                if response.status_code == 200:
                    commits = response.json()
                    if commits:  # è¿™ä¸€é¡µæœ‰æ•°æ®
                        last_valid_page = mid
                        left = mid + 1
                    else:  # è¿™ä¸€é¡µæ²¡æ•°æ®ï¼Œè¯´æ˜è¶…å‡ºäº†
                        right = mid - 1
                else:
                    right = mid - 1
            except:
                right = mid - 1
        
        return last_valid_page
    
    def _fetch_all_pages_concurrent(self, branch_name: str, total_pages: int) -> List[Dict[str, Any]]:
        """å¹¶å‘è·å–æ‰€æœ‰é¡µé¢çš„commits"""
        all_commits = []
        
        def fetch_page(page_num: int) -> Dict[str, Any]:
            """è·å–å•é¡µcommits"""
            page_start = time.time()
            url = f"{self.gitlab_url}/api/v4/projects/{self.project_id}/repository/commits"
            params = {
                'ref_name': branch_name,
                'per_page': self.config['per_page'],
                'page': page_num
            }
            
            for attempt in range(self.config['retry_attempts']):
                try:
                    response = requests.get(
                        url, 
                        headers=self.headers, 
                        params=params, 
                        timeout=self.config['timeout']
                    )
                    page_time = time.time() - page_start
                    
                    if response.status_code == 200:
                        commits = response.json()
                        # ç®€åŒ–commitæ•°æ®ï¼Œåªä¿ç•™å¿…è¦å­—æ®µ
                        simplified_commits = []
                        for commit in commits:
                            simplified_commits.append({
                                'id': commit.get('id'),
                                'message': commit.get('message', ''),
                                'author_name': commit.get('author_name', ''),
                                'committed_date': commit.get('committed_date', ''),
                                'short_id': commit.get('short_id', '')
                            })
                        
                        return {
                            'page': page_num,
                            'commits': simplified_commits,
                            'count': len(simplified_commits),
                            'time': page_time,
                            'success': True,
                            'attempt': attempt + 1
                        }
                    else:
                        if attempt == self.config['retry_attempts'] - 1:  # æœ€åä¸€æ¬¡å°è¯•
                            return {
                                'page': page_num,
                                'commits': [],
                                'count': 0,
                                'time': page_time,
                                'success': False,
                                'error': f'HTTP {response.status_code}',
                                'attempt': attempt + 1
                            }
                        time.sleep(0.5 * (attempt + 1))  # é€’å¢å»¶è¿Ÿé‡è¯•
                        
                except Exception as e:
                    page_time = time.time() - page_start
                    if attempt == self.config['retry_attempts'] - 1:  # æœ€åä¸€æ¬¡å°è¯•
                        return {
                            'page': page_num,
                            'commits': [],
                            'count': 0,
                            'time': page_time,
                            'success': False,
                            'error': str(e),
                            'attempt': attempt + 1
                        }
                    time.sleep(0.5 * (attempt + 1))  # é€’å¢å»¶è¿Ÿé‡è¯•
        
        # å¹¶å‘è·å–æ‰€æœ‰é¡µé¢
        logger.info(f"[{self._timestamp()}] ğŸ”„ å¯åŠ¨ {self.config['max_workers']} ä¸ªå¹¶å‘workerå¤„ç† {total_pages} é¡µ")
        
        with ThreadPoolExecutor(max_workers=self.config['max_workers']) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = []
            for page in range(1, total_pages + 1):
                future = executor.submit(fetch_page, page)
                futures.append(future)
            
            # æ”¶é›†ç»“æœ
            successful_pages = 0
            failed_pages = 0
            total_fetch_time = 0
            
            for future in as_completed(futures):
                result = future.result()
                if result['success']:
                    all_commits.extend(result['commits'])
                    successful_pages += 1
                else:
                    failed_pages += 1
                    logger.warning(f"[{self._timestamp()}] âš ï¸ é¡µé¢ {result['page']} è·å–å¤±è´¥: {result.get('error', 'unknown')}")
                
                total_fetch_time += result['time']
        
        avg_page_time = total_fetch_time / len(futures) if futures else 0
        
        logger.info(f"[{self._timestamp()}] ğŸ“Š å¹¶å‘è·å–ç»Ÿè®¡: æˆåŠŸ {successful_pages} é¡µ, å¤±è´¥ {failed_pages} é¡µ, å¹³å‡é¡µé¢è€—æ—¶ {avg_page_time:.2f}s")
        
        return all_commits
    
    def extract_branch_tasks_local(self, commits: List[Dict[str, Any]]) -> Set[str]:
        """
        æœ¬åœ°æå–tasksï¼Œé¿å…APIè°ƒç”¨
        ç›¸æ¯”é€ä¸ªæœç´¢ï¼Œè¿™ä¸ªæ–¹æ³•å‡ ä¹ç¬é—´å®Œæˆ
        """
        start_time = time.time()
        tasks = set()
        
        for commit in commits:
            message = commit.get('message', '')
            matches = self.task_pattern.findall(message)
            tasks.update(f"GALAXY-{match}" for match in matches)
        
        elapsed = time.time() - start_time
        logger.info(f"[{self._timestamp()}] ğŸ§® æœ¬åœ°taskæå–å®Œæˆ: {len(commits)} commits -> {len(tasks)} tasks, è€—æ—¶ {elapsed:.3f}s")
        
        return tasks
    
    def get_version_diff_optimized(self, from_version: str, to_version: str) -> List[Dict[str, Any]]:
        """
        ä¼˜åŒ–ç‰ˆæœ¬çš„ç‰ˆæœ¬å·®å¼‚è·å–
        ä¿æŒä¸åŸæ–¹æ³•çš„å…¼å®¹æ€§
        """
        cache_key = CacheKey.version_diff(from_version, to_version)
        
        cached_result = self.cache.get(cache_key)
        if cached_result is not None:
            logger.info(f"[{self._timestamp()}] ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„ç‰ˆæœ¬å·®å¼‚")
            return cached_result
        
        try:
            logger.info(f"[{self._timestamp()}] ğŸ” è·å–ç‰ˆæœ¬å·®å¼‚: {from_version} -> {to_version}")
            comparison = self.project.repository_compare(
                from_=from_version, 
                to=to_version
            )
            diff_commits = comparison.get('commits', [])
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            commits_data = []
            for commit in diff_commits:
                commits_data.append({
                    'id': commit.get('id'),
                    'message': commit.get('message', ''),
                    'author_name': commit.get('author_name', ''),
                    'committed_date': commit.get('committed_date', ''),
                    'short_id': commit.get('short_id', '')
                })
            
            self.cache.set(cache_key, commits_data)
            logger.info(f"[{self._timestamp()}] âœ… ç‰ˆæœ¬å·®å¼‚è·å–å®Œæˆ: {len(commits_data)} commits")
            return commits_data
            
        except Exception as e:
            logger.error(f"[{self._timestamp()}] âŒ è·å–ç‰ˆæœ¬å·®å¼‚å¤±è´¥: {e}")
            return []
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'config': self.config,
            'cache_stats': self.cache.get_stats(),
            'timestamp': self._timestamp()
        }
    
    def clear_cache(self) -> None:
        """æ¸…ç†ç¼“å­˜"""
        self.cache.clear()
        logger.info(f"[{self._timestamp()}] ğŸ§¹ OptimizedGitLabManagerç¼“å­˜å·²æ¸…ç†")


class OptimizedGitLabAPIError(Exception):
    """ä¼˜åŒ–ç‰ˆGitLab APIå¼‚å¸¸"""
    pass 