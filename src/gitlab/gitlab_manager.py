#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GitLab APIç®¡ç†å™¨ v2
åŸºäºå¹¶å‘åˆ†é¡µè·å–çš„é«˜æ€§èƒ½ç‰ˆæœ¬ï¼Œç®€åŒ–é€»è¾‘ï¼Œå¢å¼ºæ—¥å¿—
"""
import re
import time
import logging
from typing import List, Dict, Any, Optional, Set
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import requests

# ç¡®ä¿å¯¼å…¥æ­£ç¡®çš„gitlabåŒ…ï¼Œé¿å…ä¸æœ¬åœ°æ¨¡å—å†²çª
import sys
import importlib
# ä¸´æ—¶ç§»é™¤æœ¬åœ°è·¯å¾„ï¼Œç¡®ä¿å¯¼å…¥python-gitlabåŒ…
current_path = sys.path[:]
sys.path = [p for p in sys.path if not p.endswith('src')]
gitlab = importlib.import_module('gitlab')
sys.path = current_path


logger = logging.getLogger(__name__)


class GitLabManager:
    """GitLab APIç®¡ç†å™¨ - é«˜æ€§èƒ½ç‰ˆæœ¬"""
    
    def __init__(self, gitlab_url: str, token: str, project_id: str):
        self.gitlab_url = gitlab_url
        self.token = token
        self.project_id = project_id
        
        # åˆå§‹åŒ–GitLabè¿æ¥
        self.gitlab = gitlab.Gitlab(gitlab_url, private_token=token)
        self.project = self.gitlab.projects.get(project_id)
        
        # Taskæ­£åˆ™è¡¨è¾¾å¼ - æ”¯æŒGALAXY-XXXå’ŒOP-XXXæ ¼å¼
        self.task_pattern = re.compile(r'(GALAXY-\d+|OP-\d+)')
        
        # æ€§èƒ½é…ç½®
        self.config = {
            'per_page': 100,        # æ¯é¡µcommitsæ•°é‡ï¼Œé™ä½åˆ°100é¿å…è¶…æ—¶
            'max_workers': 8,       # å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°ï¼Œé™ä½é¿å…è¿‡è½½
            'timeout': 30,          # è¯·æ±‚è¶…æ—¶æ—¶é—´
            'retry_attempts': 3,    # é‡è¯•æ¬¡æ•°
        }
        
        # ç”¨äºç›´æ¥APIè°ƒç”¨çš„headers
        self.headers = {
            'PRIVATE-TOKEN': token,
            'Content-Type': 'application/json'
        }
        
        logger.info(f"[{self._timestamp()}] ğŸš€ GitLabManageråˆå§‹åŒ–å®Œæˆ: {gitlab_url}, é¡¹ç›®ID: {project_id}")
        logger.info(f"[{self._timestamp()}] âš™ï¸ é…ç½®: æ¯é¡µ{self.config['per_page']}ä¸ªcommits, {self.config['max_workers']}ä¸ªå¹¶å‘worker")
    
    def _timestamp(self) -> str:
        """ç”Ÿæˆå¸¦æ¯«ç§’çš„æ—¶é—´æˆ³"""
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
    
    def get_all_tag_commits(self, tag_name: str) -> List[Dict[str, Any]]:
        """
        è·å–tagçš„æ‰€æœ‰commits - ç®€åŒ–ç‰ˆæœ¬ï¼Œé€é¡µè·å–ç›´åˆ°æ²¡æœ‰æ•°æ®
        """
        start_time = time.time()
        logger.info(f"[{self._timestamp()}] ğŸ“¥ å¼€å§‹è·å–tag commits: {tag_name}")
        
        all_commits = []
        page = 1
        total_pages = 0
        
        while True:
            logger.info(f"[{self._timestamp()}] ğŸ“„ æ­£åœ¨è·å–ç¬¬ {page} é¡µ...")
            
            page_commits = self._fetch_single_page(tag_name, page)
            
            if not page_commits:
                logger.info(f"[{self._timestamp()}] ğŸ ç¬¬ {page} é¡µæ²¡æœ‰æ•°æ®ï¼Œè·å–å®Œæˆ")
                total_pages = page - 1
                break
            
            all_commits.extend(page_commits)
            logger.info(f"[{self._timestamp()}] âœ… ç¬¬ {page} é¡µè·å–åˆ° {len(page_commits)} ä¸ªcommitsï¼Œç´¯è®¡ {len(all_commits)} ä¸ª")
            
            # å¦‚æœè¿™ä¸€é¡µçš„æ•°æ®å°‘äºæ¯é¡µé…ç½®æ•°é‡ï¼Œè¯´æ˜æ˜¯æœ€åä¸€é¡µ
            if len(page_commits) < self.config['per_page']:
                logger.info(f"[{self._timestamp()}] ğŸ ç¬¬ {page} é¡µæ•°æ®ä¸è¶³ {self.config['per_page']} ä¸ªï¼Œç¡®è®¤ä¸ºæœ€åä¸€é¡µ")
                total_pages = page
                break
            
            page += 1
            
            # å®‰å…¨æ£€æŸ¥ï¼Œé¿å…æ— é™å¾ªç¯
            if page > 1000:
                logger.warning(f"[{self._timestamp()}] âš ï¸ é¡µæ•°è¶…è¿‡1000ï¼Œå¼ºåˆ¶åœæ­¢")
                total_pages = page - 1
                break
        
        elapsed = time.time() - start_time
        logger.info(f"[{self._timestamp()}] ğŸ¯ è·å–å®Œæˆç»Ÿè®¡:")
        logger.info(f"    ğŸ“Š Tag: {tag_name}")
        logger.info(f"    ğŸ“Š æ€»é¡µæ•°: {total_pages}")
        logger.info(f"    ğŸ“Š æ€»commits: {len(all_commits)}")
        logger.info(f"    ğŸ“Š è€—æ—¶: {elapsed:.2f}s")
        logger.info(f"    ğŸ“Š é€Ÿåº¦: {len(all_commits)/elapsed:.1f} commits/s")
        
        return all_commits
    
    def _fetch_single_page(self, ref_name: str, page: int) -> List[Dict[str, Any]]:
        """è·å–å•é¡µcommits"""
        url = f"{self.gitlab_url}/api/v4/projects/{self.project_id}/repository/commits"
        params = {
            'ref_name': ref_name,
            'per_page': self.config['per_page'],
            'page': page
        }
        
        for attempt in range(self.config['retry_attempts']):
            try:
                logger.debug(f"[{self._timestamp()}] ğŸ”— è¯·æ±‚ç¬¬ {page} é¡µ (å°è¯• {attempt + 1}/{self.config['retry_attempts']})")
                
                response = requests.get(
                    url, 
                    headers=self.headers, 
                    params=params, 
                    timeout=self.config['timeout']
                )
                
                if response.status_code == 200:
                    commits = response.json()
                    
                    # ç®€åŒ–commitæ•°æ®ï¼Œåªä¿ç•™å¿…è¦å­—æ®µ
                    simplified_commits = []
                    for commit in commits:
                        simplified_commits.append({
                            'id': commit.get('id'),
                            'message': commit.get('message', ''),
                            'author_name': commit.get('author_name', ''),
                            'committed_date': commit.get('committed_date', ''),
                            'short_id': commit.get('short_id', '')
                        })
                    
                    logger.debug(f"[{self._timestamp()}] âœ… ç¬¬ {page} é¡µè¯·æ±‚æˆåŠŸï¼Œè·å– {len(simplified_commits)} ä¸ªcommits")
                    return simplified_commits
                    
                elif response.status_code == 404:
                    logger.warning(f"[{self._timestamp()}] âš ï¸ ç¬¬ {page} é¡µè¿”å›404ï¼Œå¯èƒ½å·²åˆ°æœ«å°¾")
                    return []
                    
                else:
                    logger.warning(f"[{self._timestamp()}] âš ï¸ ç¬¬ {page} é¡µè¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                    if attempt == self.config['retry_attempts'] - 1:
                        return []
                    time.sleep(0.5 * (attempt + 1))
                    
            except Exception as e:
                logger.warning(f"[{self._timestamp()}] âš ï¸ ç¬¬ {page} é¡µè¯·æ±‚å¼‚å¸¸: {e}")
                if attempt == self.config['retry_attempts'] - 1:
                    return []
                time.sleep(0.5 * (attempt + 1))
        
        return []
    
    def get_all_tag_commits_concurrent(self, tag_name: str) -> List[Dict[str, Any]]:
        """
        å¹¶å‘è·å–tagçš„æ‰€æœ‰commits - å…ˆæ¢æµ‹æ€»é¡µæ•°ï¼Œå†å¹¶å‘è·å–
        """
        start_time = time.time()
        logger.info(f"[{self._timestamp()}] ğŸ“¥ å¼€å§‹å¹¶å‘è·å–tag commits: {tag_name}")
        
        # ç¬¬ä¸€æ­¥ï¼šæ¢æµ‹æ€»é¡µæ•°
        logger.info(f"[{self._timestamp()}] ğŸ” ç¬¬ä¸€æ­¥ï¼šæ¢æµ‹æ€»é¡µæ•°...")
        total_pages = self._detect_total_pages(tag_name)
        
        if total_pages == 0:
            logger.warning(f"[{self._timestamp()}] âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•é¡µé¢ï¼Œtagå¯èƒ½ä¸å­˜åœ¨æˆ–æ²¡æœ‰commits")
            return []
        
        logger.info(f"[{self._timestamp()}] ğŸ“Š æ£€æµ‹åˆ°æ€»é¡µæ•°: {total_pages}")
        
        # ç¬¬äºŒæ­¥ï¼šå¹¶å‘è·å–æ‰€æœ‰é¡µé¢
        logger.info(f"[{self._timestamp()}] ğŸš€ ç¬¬äºŒæ­¥ï¼šå¹¶å‘è·å– {total_pages} é¡µ...")
        all_commits = self._fetch_all_pages_concurrent(tag_name, total_pages)
        
        elapsed = time.time() - start_time
        logger.info(f"[{self._timestamp()}] ğŸ¯ å¹¶å‘è·å–å®Œæˆç»Ÿè®¡:")
        logger.info(f"    ğŸ“Š Tag: {tag_name}")
        logger.info(f"    ğŸ“Š æ€»é¡µæ•°: {total_pages}")
        logger.info(f"    ğŸ“Š æ€»commits: {len(all_commits)}")
        logger.info(f"    ğŸ“Š è€—æ—¶: {elapsed:.2f}s")
        logger.info(f"    ğŸ“Š é€Ÿåº¦: {len(all_commits)/elapsed:.1f} commits/s")
        
        return all_commits
    
    def _detect_total_pages(self, ref_name: str) -> int:
        """æ¢æµ‹æ€»é¡µæ•° - ç®€å•æ–¹æ¡ˆï¼Œé€é¡µæ£€æŸ¥ç›´åˆ°æ²¡æœ‰æ•°æ®"""
        logger.info(f"[{self._timestamp()}] ğŸ” å¼€å§‹æ¢æµ‹ {ref_name} çš„æ€»é¡µæ•°...")
        
        # å…ˆæ£€æŸ¥ç¬¬1é¡µ
        first_page = self._fetch_single_page(ref_name, 1)
        if not first_page:
            logger.info(f"[{self._timestamp()}] ğŸ“Š ç¬¬1é¡µæ²¡æœ‰æ•°æ®ï¼Œæ€»é¡µæ•°: 0")
            return 0
        
        if len(first_page) < self.config['per_page']:
            logger.info(f"[{self._timestamp()}] ğŸ“Š ç¬¬1é¡µåªæœ‰ {len(first_page)} ä¸ªcommitsï¼Œæ€»é¡µæ•°: 1")
            return 1
        
        # ä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾å¿«é€Ÿå®šä½æœ€åä¸€é¡µ
        left, right = 1, 500  # å‡è®¾æœ€å¤š500é¡µ
        last_valid_page = 1
        
        logger.info(f"[{self._timestamp()}] ğŸ” ä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾æ¢æµ‹æœ€åä¸€é¡µ (èŒƒå›´: 1-{right})")
        
        while left <= right:
            mid = (left + right) // 2
            logger.debug(f"[{self._timestamp()}] ğŸ” æ£€æŸ¥ç¬¬ {mid} é¡µ...")
            
            page_data = self._fetch_single_page(ref_name, mid)
            
            if page_data:  # è¿™ä¸€é¡µæœ‰æ•°æ®
                last_valid_page = mid
                left = mid + 1
                logger.debug(f"[{self._timestamp()}] âœ… ç¬¬ {mid} é¡µæœ‰ {len(page_data)} ä¸ªcommitsï¼Œç»§ç»­å‘å³æŸ¥æ‰¾")
            else:  # è¿™ä¸€é¡µæ²¡æ•°æ®ï¼Œè¯´æ˜è¶…å‡ºäº†
                right = mid - 1
                logger.debug(f"[{self._timestamp()}] âŒ ç¬¬ {mid} é¡µæ²¡æœ‰æ•°æ®ï¼Œå‘å·¦æŸ¥æ‰¾")
        
        logger.info(f"[{self._timestamp()}] ğŸ“Š æ¢æµ‹å®Œæˆï¼Œæ€»é¡µæ•°: {last_valid_page}")
        return last_valid_page
    
    def _fetch_all_pages_concurrent(self, ref_name: str, total_pages: int) -> List[Dict[str, Any]]:
        """å¹¶å‘è·å–æ‰€æœ‰é¡µé¢çš„commits"""
        all_commits = []
        
        logger.info(f"[{self._timestamp()}] ğŸ”„ å¯åŠ¨ {self.config['max_workers']} ä¸ªå¹¶å‘workerå¤„ç† {total_pages} é¡µ")
        
        with ThreadPoolExecutor(max_workers=self.config['max_workers']) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = []
            for page in range(1, total_pages + 1):
                future = executor.submit(self._fetch_single_page, ref_name, page)
                futures.append((page, future))
            
            # æ”¶é›†ç»“æœ
            successful_pages = 0
            failed_pages = 0
            
            for page_num, future in futures:
                try:
                    commits = future.result()
                    if commits:
                        all_commits.extend(commits)
                        successful_pages += 1
                        logger.debug(f"[{self._timestamp()}] âœ… ç¬¬ {page_num} é¡µæˆåŠŸè·å– {len(commits)} ä¸ªcommits")
                    else:
                        failed_pages += 1
                        logger.warning(f"[{self._timestamp()}] âŒ ç¬¬ {page_num} é¡µè·å–å¤±è´¥")
                except Exception as e:
                    failed_pages += 1
                    logger.error(f"[{self._timestamp()}] âŒ ç¬¬ {page_num} é¡µå¤„ç†å¼‚å¸¸: {e}")
        
        logger.info(f"[{self._timestamp()}] ğŸ“Š å¹¶å‘è·å–ç»Ÿè®¡: æˆåŠŸ {successful_pages} é¡µ, å¤±è´¥ {failed_pages} é¡µ")
        
        return all_commits
    
    def extract_commit_messages_with_tasks(self, commits: List[Dict[str, Any]]) -> Dict[str, str]:
        """
        ä»commitsä¸­æå–åŒ…å«taskçš„commit message
        åŸºäºtask IDå’Œmessageç¬¬ä¸€è¡Œçš„ç»„åˆæ¥åˆ¤æ–­ï¼Œå¿½ç•¥cherry-pickç­‰å·®å¼‚
        
        Args:
            commits: commitåˆ—è¡¨
            
        Returns:
            Dict[str, str]: {task_id_with_first_line: primary_task_id} æ˜ å°„
        """
        start_time = time.time()
        logger.info(f"[{self._timestamp()}] ğŸ§® å¼€å§‹ä» {len(commits)} ä¸ªcommitsä¸­æå–taskç›¸å…³çš„commit messages...")
        
        commit_task_map = {}
        
        for i, commit in enumerate(commits):
            message = commit.get('message', '').strip()
            # æŸ¥æ‰¾åŒ…å«task IDçš„commit message
            found_tasks = self.task_pattern.findall(message)
            if found_tasks:
                # æå–messageçš„ç¬¬ä¸€è¡Œ
                first_line = message.split('\n')[0].strip()
                
                # ä¸ºæ¯ä¸ªæ‰¾åˆ°çš„task IDéƒ½åˆ›å»ºä¸€ä¸ªè®°å½•
                # è¿™æ ·å¯ä»¥å¤„ç†ä¸€ä¸ªcommitåŒ…å«å¤šä¸ªtaskçš„æƒ…å†µ
                for task_id in found_tasks:
                    # ä½¿ç”¨task ID + ç¬¬ä¸€è¡Œä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œè¿™æ ·å¯ä»¥ï¼š
                    # 1. é¿å…cherry-pickä¿¡æ¯çš„å¹²æ‰°
                    # 2. ä¿ç•™æ ¸å¿ƒçš„åŠŸèƒ½æè¿°ä¿¡æ¯
                    # 3. åŒä¸€ä¸ªtaskçš„ä¸åŒcommitä»ç„¶èƒ½è¢«åŒºåˆ†
                    # 4. ä¸€ä¸ªcommitåŒ…å«å¤šä¸ªtaskæ—¶ï¼Œæ¯ä¸ªtaskéƒ½èƒ½è¢«æ­£ç¡®è¯†åˆ«
                    task_with_first_line = f"{task_id}||{first_line}"
                    commit_task_map[task_with_first_line] = task_id
            
            if (i + 1) % 1000 == 0:  # æ¯1000ä¸ªcommitsæ‰“å°ä¸€æ¬¡è¿›åº¦
                logger.debug(f"[{self._timestamp()}] ğŸ“Š å·²å¤„ç† {i + 1}/{len(commits)} ä¸ªcommitsï¼Œå½“å‰æ‰¾åˆ° {len(commit_task_map)} ä¸ªtaskç›¸å…³commits")
        
        elapsed = time.time() - start_time
        logger.info(f"[{self._timestamp()}] ğŸ¯ Commit messageæå–å®Œæˆ:")
        logger.info(f"    ğŸ“Š å¤„ç†commits: {len(commits)} ä¸ª")
        logger.info(f"    ğŸ“Š åŒ…å«taskçš„commits: {len(commit_task_map)} ä¸ª")
        logger.info(f"    ğŸ“Š è€—æ—¶: {elapsed:.3f}s")
        logger.info(f"    ğŸ“Š ä½¿ç”¨task ID + ç¬¬ä¸€è¡Œç»„åˆ (å¿½ç•¥cherry-pickå’Œå…¶ä»–å·®å¼‚)")
        
        if commit_task_map:
            # æ˜¾ç¤ºå‰å‡ ä¸ªç¤ºä¾‹
            sample_items = list(commit_task_map.items())[:5]
            logger.info(f"    ğŸ“Š å‰5ä¸ªç¤ºä¾‹:")
            for key, task in sample_items:
                # æå–ç¬¬ä¸€è¡Œç”¨äºæ˜¾ç¤º
                first_line = key.split('||')[1] if '||' in key else key
                short_msg = first_line[:50] + "..." if len(first_line) > 50 else first_line
                logger.info(f"        {task}: {short_msg}")
        
        return commit_task_map
    
    def extract_tasks_from_commits(self, commits: List[Dict[str, Any]]) -> Set[str]:
        """
        ä»commitsä¸­æå–tasksï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
        """
        commit_task_map = self.extract_commit_messages_with_tasks(commits)
        return set(commit_task_map.values())
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        return {
            'config': self.config,
            'gitlab_url': self.gitlab_url,
            'project_id': self.project_id
        }
    
    def _normalize_commit_message(self, message: str) -> str:
        """
        æ ‡å‡†åŒ–commit messageï¼Œç§»é™¤cherry-pickç­‰ä¿¡æ¯ä»¥ä¾¿å‡†ç¡®æ¯”è¾ƒ
        
        Args:
            message: åŸå§‹commit message
            
        Returns:
            æ ‡å‡†åŒ–åçš„commit message
        """
        # ç§»é™¤cherry-pickä¿¡æ¯
        # æ ¼å¼: (cherry picked from commit xxx)
        import re
        
        # ç§»é™¤cherry-pickè¡ŒåŠå…¶å‰é¢çš„ç©ºè¡Œ
        normalized = re.sub(r'\n*\(cherry picked from commit [a-f0-9]+\)\s*$', '', message, flags=re.MULTILINE)
        
        # ç§»é™¤æœ«å°¾çš„å¤šä½™ç©ºç™½å­—ç¬¦
        normalized = normalized.rstrip()
        
        return normalized 